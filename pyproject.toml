[build-system]
requires = ["setuptools", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools]
packages = ["libhaa"]

[project]
name = "libhaa"
authors = [
    {name = "Artur Jurgas", email = "arjurgas@outlook.com"},
]
version = "0.1.0"
description = "Package for WSI augmentation with artifacts."
readme = "README.md"
requires-python = ">=3.10"
keywords = ["histopathology", "image-augmentation"]
license = {text = "Under review"}
classifiers = [
    "Programming Language :: Python :: 3",
]
dependencies = [
    "Pillow",
    "numpy < 2.0",
    "opencv-python",
    "scipy",
    "staintools",
    "spams-bin",
    "ruamel.yaml",
    # "pyvips-binary", # not working with openslideload
    "pyvips",
    # "openslide-bin", # will work after openslide-python 1.4 will be released
    "openslide-python",
    "tqdm"
]


[project.optional-dependencies]
all = [
    "libhaa[histo-seg]",
    "libhaa[histo-class]",
]

histo-seg = [
    "torch",
    "torchio",
    #...
]
histo-class = [
    "torch",
    "pytorch_lightning",
    "pandas",
    "torchmetrics",
    "palettable",
    "mpltex",
    #...
]

[project.scripts]
build-collection = "libhaa.scripts.build_collection:cli"
generate-dataset = "libhaa.scripts.generate_dataset:cli"
segment = "libhaa.scripts.segment:cli"
cut-patches-training = "libhaa.scripts.cut_patches:cli_cut_for_training"
cut-patches-inference = "libhaa.scripts.cut_patches:cli_cut_for_inference"
classify = "libhaa.scripts.classify:run_inference"
xml-to-tiff = "libhaa.scripts.generate_mask_from_xml:cli"